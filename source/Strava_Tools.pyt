# -*- coding: utf-8 -*-import arcpyimport jsonimport requestsimport datetimeimport polylineimport pandasclass Toolbox(object):    def __init__(self):        """Define the toolbox (the name of the toolbox is the name of the        .pyt file)."""        self.label = "Strava_Tools"        self.alias = "Strava Tools"        # List of tool classes associated with this toolbox        self.tools = [ImportActivityRoutes]class ImportActivityRoutes(object):    def __init__(self):        """Define the tool (tool name is the name of the class)."""        self.label = "Import Strava Activity Routes to Feature Class"        self.description = "Imports activities from the Strava API and generates a feature class of POLYLINE routes, with metadata fields."        self.canRunInBackground = False    def getParameterInfo(self):        """Define parameter definitions"""        """ Requires: displayName, name, datatype, parameterType, direction """        workspace = arcpy.Parameter(displayName="Local Database Workspace",name="workspace",datatype="DEWorkspace",parameterType="Required",direction="Input")        workspace.defaultEnvironmentName = "workspace"        workspace.filter.list = ["Local Database"]        overwriteOutput = arcpy.Parameter(displayName="Overwrite Output",name="overwriteOutput",datatype="GPBoolean",parameterType="Required",direction="Input")        overwriteOutput.value = True        endDatetimeString = arcpy.Parameter(displayName="Ending Date & Time",name="endDatetimeString",datatype="GPDate",parameterType="Required",direction="Input")        endDatetimeObj = datetime.datetime.now()        endDatetimeString.value = endDatetimeObj        startDatetimeString = arcpy.Parameter(displayName="Starting Date & Time",name="startDatetimeString",datatype="GPDate",parameterType="Required",direction="Input")        startDatetimeObj = datetime.datetime.now() - datetime.timedelta(days=30)        startDatetimeString.value = startDatetimeObj        activityTypeSubstring = arcpy.Parameter(displayName="Activity Type",name="activityTypeSubstring",datatype="GPString",parameterType="Required",direction="Input")        activityTypeSubstring.filter.type = "ValueList"        activityTypeSubstring.filter.list = ["AlpineSki", "BackcountrySki", "Canoeing", "EBikeRide", "Elliptical", "Golf", "Hike", "IceSkate", "InlineSkate", "Kayaking", "Kitesurf", "NordicSki", "Ride", "RollerSki", "Rowing", "Run", "Sail", "Skateboard", "Snowboard", "Snowshoe",  "StandUpPaddling", "Surfing", "Swim", "Velomobile", "VirtualRide", "VirtualRun", "Walk"]        activityTypeSubstring.value = "Run"        srid = arcpy.Parameter(displayName="Spatial Reference ID",name="srid",datatype="GPLong",parameterType="Required",direction="Input")        srid.value=4326        pathToStravaCredsJson = arcpy.Parameter(displayName="File Path to Strava API Credentials JSON",name="pathToStravaCredsJson",datatype="DEFile",parameterType="Required",direction="Input")        pathToStravaCredsJson.filter.list = ["json"]                outFcName = arcpy.Parameter(displayName="Output Feature Class",name="outputFcName",datatype="DEFeatureClass",parameterType="Required",direction="Output")        outFcName.value = "StravaRoutesImport"        verbose = arcpy.Parameter(displayName="Verbose Logging",name="verbose",datatype="GPBoolean",parameterType="Required",direction="Input")        verbose.value = True                params = [workspace,overwriteOutput,pathToStravaCredsJson,outFcName,startDatetimeString,endDatetimeString,activityTypeSubstring,srid, verbose]        return params    def isLicensed(self):        """Set whether tool is licensed to execute."""        return True    def updateParameters(self, parameters):        """Modify the values and properties of parameters before internal        validation is performed.  This method is called whenever a parameter        has been changed."""                return    def updateMessages(self, parameters):        """Modify the messages created by internal validation for each tool        parameter.  This method is called after internal validation."""        #Need to validate proper formatting of JSON file here        if parameters[2].value:            pathToStravaCredsJson = parameters[2]            path_to_creds_dict = pathToStravaCredsJson.valueAsText            proper_json_format_example = "{\"strava\": \n\t{\"client_id\": 12345,\n\t\"client_secret\": \"1a2b3c.....4d5e\",\n\t\"access_token\": \"1a2b3c.....4d5e\",\n\t\"refresh_token\": \"1a2b3c.....4d5e\",\n\t\"expires_at\":1111...111 <-- **the tool will populate this value**}\n}"            from json.decoder import JSONDecodeError            try:                with open(path_to_creds_dict, "r") as input_json:                    creds_dict = json.load(input_json)            except FileNotFoundError as e:                pathToStravaCredsJson.setErrorMessage(f"`{path_to_creds_dict}` not found:",e)            except json.decoder.JSONDecodeError:                pathToStravaCredsJson.setErrorMessage(f"`{path_to_creds_dict}` is not a properly formatted JSON object. Use the format:\n"+proper_json_format_example)            #top-level strava key should be present            if not(pathToStravaCredsJson.hasError()):                if not("strava" in creds_dict.keys()):                    pathToStravaCredsJson.setErrorMessage(f"`strava` element not present in `{path_to_creds_dict}`. Use the format:\n"+proper_json_format_example)                else:                    strava = creds_dict['strava']                    diff = set(["client_id", "client_secret", "access_token", "refresh_token"]) - set(strava.keys())                    #the output diff set should be empty                    if diff:                        pathToStravaCredsJson.setErrorMessage(f"One of [`client_id`, `client_secret`, `access_token`, `refresh_token`] are missing from {path_to_creds_dict}. Use the format:\n"+proper_json_format_example)                    #If all fields exist, check their value types                    else:                        type_test = (type(strava["client_secret"]) == type(strava["access_token"]) == type(strava["refresh_token"]) == str) and (type(strava["client_id"]) == int)                        if not(type_test):                            pathToStravaCredsJson.setErrorMessage(f"One of [`client_id`, `client_secret`, `access_token`, `refresh_token`] in `{path_to_creds_dict}` are the wrong data type. Use the format:\n"+proper_json_format_example)        #Validate the Start Date is BEFORE the End Date        startDatetimeParameter = parameters[4]        endDatetimeParameter = parameters[5]        if startDatetimeParameter.value and endDatetimeParameter.value:            if startDatetimeParameter.value > endDatetimeParameter.value:                endDatetimeParameter.setErrorMessage(f"The Ending Date & Time must be AFTER the Starting Date & Time.")        #Check that it's a valid Spatial Reference ID (authority code, aka WKID)        sridParameter = parameters[7]        if sridParameter.value:            try:                arcpy.SpatialReference(sridParameter.value)            except:                sridParameter.setErrorMessage("Invalid Spatial Reference Well-Known ID.")        return    def execute(self, parameters, messages):        """The source code of the tool."""        workspace = parameters[0]        overwriteOutput = parameters[1]        pathToStravaCredsJson = parameters[2]        outFcName = parameters[3]        startDatetimeString = parameters[4]        endDatetimeString = parameters[5]        activityTypeSubstring = parameters[6]        srid = parameters[7]        verbose = parameters[8]        #Set ArcPy environment using parameters        arcpy.env.workspace = workspace.valueAsText        arcpy.env.overwriteOutput = overwriteOutput.value                #Convert datetimes to UTC        startDatetimeObj_UTC = startDatetimeString.value.astimezone().astimezone(datetime.timezone.utc)        endDatetimeObj_UTC = endDatetimeString.value.astimezone().astimezone(datetime.timezone.utc)        #Format output feature class parameter to just the name, not the path        formatted_output_FC_name = outFcName.valueAsText.split("\\")[-1]        #Define function inputs        tool_kwargs = {            "out_path": arcpy.env.workspace,            "out_fc_name":formatted_output_FC_name,            "path_to_strava_creds_json":pathToStravaCredsJson.valueAsText,            "start_datetime_string":startDatetimeObj_UTC.strftime('%Y-%m-%d %H:%M:%S'),            "end_datetime_string":endDatetimeObj_UTC.strftime('%Y-%m-%d %H:%M:%S'),            "activity_type_substring":activityTypeSubstring.valueAsText,            "srid":srid.value,            "verbose":verbose.value        }        #Finally - execute the actual functions here (defined below)        list_of_coordinate_dictionaries = get_activity_routes(tool_kwargs["path_to_strava_creds_json"], \                                                          tool_kwargs["start_datetime_string"], tool_kwargs["end_datetime_string"], \                                                          tool_kwargs["activity_type_substring"], tool_kwargs["verbose"])        list_of_geometry_dicts = generate_polyline_objects(list_of_coordinate_dictionaries, tool_kwargs["srid"], tool_kwargs["verbose"])        if not(list_of_geometry_dicts is None):            created_fc_describe = create_feature_class_with_fields(tool_kwargs["out_path"], tool_kwargs["out_fc_name"], tool_kwargs["srid"], tool_kwargs["verbose"])            if not(created_fc_describe is None):                feature_class_name = created_fc_describe["name"] #this should be the same as `out_fc_name`                modified_fc_describe = populate_feature_class(feature_class_name, list_of_geometry_dicts, tool_kwargs["verbose"])        return None    def postExecute(self, parameters):        """This method takes place after outputs are processed and        added to the display."""        return""" Helper function definitions & variables """#This master `fields_list` has global scope.#Each field  has a name, type, NO alias, field length (for text), default value, NO domainfields_list = [["strava_id", "DOUBLE", '', None, None, None],    ["external_id", "TEXT", '', 128, None, None],    ["athlete_id", 'DOUBLE', '', None, None, None],    ["athlete_resource_state", 'LONG', '', None, None, None],    ["name", "TEXT", "", None, None, None],    ["distance", 'FLOAT', '', None, None, None],    ["moving_time", 'LONG', '', None, None, None],    ["elapsed_time", 'LONG', '', None, None, None],    ["total_elevation_gain", 'FLOAT', '', None, None, None],    ["elev_high", 'FLOAT', '', None, None, None],    ["elev_low", 'FLOAT', '', None, None, None],    ["type", "TEXT", '', 128, None, None],    ["sport_type", "TEXT", '', 128, None, None],    ["start_date", "DATE", '', None, None, None],    ["start_date_local", "DATE", '', None, None, None],    ["timezone", "TEXT", '', 128, None, None],    ["utc_offset", 'FLOAT', "", None, None, None],    ["location_city", "TEXT", "", 128, None, None],    ["location_state", "TEXT", '', 128, None, None],    ["location_country", "TEXT", '', 128, None, None],    ["start_lat", 'FLOAT', '', None, None, None],    ["start_lng", 'FLOAT', '', None, None, None],    ["end_lat", 'FLOAT', '', None, None, None],    ["end_lng", 'FLOAT', '', None, None, None],    ["achievement_count", 'SHORT', '', None, None, None],    ["kudos_count", 'SHORT', '', None, None, None],    ["comment_count", 'SHORT', '', None, None, None],    ["athlete_count", 'LONG', '', None, None, None],    ["photo_count", 'LONG', '', None, None, None],    ["total_photo_count", 'LONG', '', None, None, None],    ["map_id", "TEXT", '', 128, None, None],    ["map_resource_state", 'LONG', '', None, None, None],    ["map_summary_polyline", "TEXT", '', 3000, None, None],    ["trainer", "TEXT", '', 5, None, None],    ["commute", "TEXT", '', 5, None, None],    ["manual", "TEXT", '', 5, None, None],    ["private", "TEXT", '', 5, None, None],    ["flagged", "TEXT", '', 5, None, None],    ["workout_type", 'LONG', '', None, None, None],    ["upload_id_str", "TEXT", '', 128, None, None],    ["average_speed", 'FLOAT', '', None, None, None],    ["max_speed", 'FLOAT', '', None, None, None],    ["has_kudoed", "TEXT", '', 5, None, None],    ["hide_from_home", "TEXT", '', 5, None, None],    ["gear_id", "TEXT", '', 128, None, None],    ["kilojoules", 'FLOAT', '', None, None, None],    ["average_watts", 'FLOAT', '', None, None, None],    ["device_watts", "TEXT", '', 5, None, None],    ["max_watts", 'LONG', '', None, None, None],    ["weighted_average_watts", 'LONG', '', None, None, None]]#Create a list of field names in the order presented above.ordered_field_names = [field_sublist[0] for field_sublist in fields_list]#Identify boolean fields (TEXT with 5-character limit), to convert to strings laterboolean_field_names = [field_sublist[0] for field_sublist in fields_list if field_sublist[1] == "TEXT" and field_sublist[3] == 5]def obtain_api_access_info(path_to_strava_creds_json):    '''    Reads contents from JSON document into a dictionary.    Input: `path_to_strava_creds_json`, absolute path string to json document containing  API access info:            "client_id": int - 5 digit client application id            "client_secret": string - client secret (unique for your "application", i.e. your local copy of this tool)            "access_token": string - request-specific access token            "refresh_token": string - client specific refresh token            (optional) "expires_at": int - epoch seconds (10 digits) for the access token expiration                    * This value will get populated after running the tool for the first time.            Use the format: { "strava": {"client_id":...., ..., "refresh_token":...} } ***Order of keys does NOT matter    Output: Dictionary containing key-value pairs from the JSON file.    '''    try:        with open(path_to_strava_creds_json, "r") as infile:            creds_dict = json.load(infile)    except:        arcpy.AddError(f"Error loading Strava API details from `{path_to_strava_creds_json}`")    else:        return creds_dictdef refresh_access_token(creds_dict):    '''    The function uses the refresh token to obtain a new access token.    Input: `creds_dict` dictionary containing top-level "strava" key.    Output: A new dictionary of refreshed token values, with expiration date.    '''    strava = creds_dict["strava"]    response = requests.post(url = "https://www.strava.com/api/v3/oauth/token", \                             data = { \                                    'client_id':strava['client_id'],\                                    'client_secret':strava['client_secret'],\                                    'grant_type':'refresh_token',\                                    'refresh_token':strava['refresh_token']                                    }                             )    response_json = response.json()    new_creds_dict = creds_dict #copy existing values into a new dict    if "message" in response_json.keys():        arcpy.AddError("Strava API error: " + response_json["message"] + ".\nExiting.")        return None    for key, val in response_json.items():        if key in ["client_id", "client_secret", "refresh_token", "access_token", "expires_at"]:            new_creds_dict["strava"][key] = val #update relevant values in the new dict    return new_creds_dictdef check_if_expired(path_to_strava_creds_json, verbose):    '''    Calls the refresh_access_key function if Access token is expired, and refreshes if needed.    Input: `path_to_strava_creds_json`, absolute path string to json document containing  API access info    Output: Boolean (True means the keys were expired & updated; False means original keys were good to go.            (also writes to existing api key file provided as input)     '''    creds_dict = obtain_api_access_info(path_to_strava_creds_json)    if "expires_at" not in creds_dict["strava"].keys() or datetime.datetime.fromtimestamp(creds_dict["strava"]["expires_at"]) < datetime.datetime.now():        if verbose:            arcpy.AddMessage("---- Checking if API Tokens are valid. ----")            if "expires_at" in creds_dict["strava"].keys():                arcpy.AddMessage("---- Expired token. Refreshing now.")                arcpy.AddMessage("--Expiration Time: {}, Current time: {}".format(\                                                                 datetime.datetime.fromtimestamp(creds_dict["strava"]["expires_at"]),\                                                                 datetime.datetime.now()))        new_values = refresh_access_token(creds_dict)        if new_values is None:            return None #indicates an error occurred when refreshing token.        with open(path_to_strava_creds_json, "w") as outfile:            json.dump(new_values, outfile)        if verbose:            arcpy.AddMessage("---- New Expiration time: {}".format(datetime.datetime.fromtimestamp(new_values["strava"]["expires_at"])))            arcpy.AddMessage("---- Tokens within {} have been updated. Continuing.".format(path_to_strava_creds_json))        return True    else:        if verbose:            arcpy.AddMessage("---- Checking if API Tokens are valid. ----")            arcpy.AddMessage("---- Everything is good. No changes will be made")        return Falsedef get_activity_routes(path_to_strava_creds_json, start_datetime_string, end_datetime_string, activity_type_substring, verbose):     '''    Pulls (via GET) specified activity types & converts their Google Maps Polyline into Coordinates.    Input: `path_to_strava_creds_json`, absolute path string to json document containing  API access info,        `start_datetime_string`: starting datetime of activities to request from strava, in "2022-08-12 10:45:32" format        `end_datetime_string`: starting datetime of activities to request from strava, in "2022-08-12 10:45:32" format        `activity_type_substring`: case-insensitive substring that must be present in the activity type.                                    defaults to "run"    Output: List of dictionaries, one per valid activity (contains a map route), each containing two items:            The `list_of_coords` key will contain a list of coordinates [(lon, lat), ..., (lon, lat)]            The `attributes` key contains a list of metadata attribute fields, in the order of the global                            fields_list variable specified in the script.    '''    if verbose:        arcpy.AddMessage("---- Running GET request for activities from Strava. ----")    #pull api keys from json file    isKeyExpired = check_if_expired(path_to_strava_creds_json, verbose=verbose)    if isKeyExpired is None:        return None #indicates an error occurred when refreshing key    creds_dict = obtain_api_access_info(path_to_strava_creds_json)    strava = creds_dict["strava"]    #convert argument times into epoch format for inclusion in GET request    try:        start_epoch_format = datetime.datetime.strptime(start_datetime_string, '%Y-%m-%d %H:%M:%S').timestamp()        end_epoch_format = datetime.datetime.strptime(end_datetime_string, '%Y-%m-%d %H:%M:%S').timestamp()      except:        arcpy.AddError("Error occurred when converting input datetime strings in `get_activity_routes()` function")        return None    if verbose:        arcpy.AddMessage("---- Obtaining Strava {} data from {} to {}".format(activity_type_substring, start_datetime_string, end_datetime_string))    #construct the HTTPS target    base_url="https://www.strava.com/api/v3/athlete/activities"    full_url=base_url+"/?access_token="+strava['access_token']    #construct the GET request to obtain list of activities,    # using parameters of access_token, after, and before.    max_activities_per_page = 200 #Strava API returns a max of 200 activities per page; requires pagination for more results    list_of_activities = []    for page_num in range(1,11):        activities = requests.get(base_url, \                                       params={\                                               "access_token":strava['access_token'],\                                               "after":start_epoch_format,\                                               "before":end_epoch_format,\                                               "page":page_num,\                                               "per_page":max_activities_per_page                                               }\                                      )        paginated_list_of_activities = activities.json()        #If a dictionary is returned, instead of a list of events, it usually indicates an error with a message        if type(paginated_list_of_activities) == dict:            if "message" in paginated_list_of_activities.keys():                arcpy.AddError("Strava API error: " + paginated_list_of_activities["message"] + ".\nExiting")                return None        list_of_activities.extend(paginated_list_of_activities)        if len(paginated_list_of_activities) < max_activities_per_page:            break    if verbose:        arcpy.AddMessage(f"---- Strava returned {len(list_of_activities)} activities.")    list_of_event_dictionaries = []    #populate list_of_event_dictionaries with a dictionary for each route    # The "coord_list" key contains a list of lon, lat tuples, and the "attributes" key contains a dictionary of feature attributes (metadata)    for event in list_of_activities:        if activity_type_substring.lower() in event["type"].lower() and "map" in event.keys():            if "summary_polyline" not in event["map"].keys():                continue #skip events without a summary polyline            activity_polyline = event["map"]["summary_polyline"]            #Unpack nested json; replace periods in column names with underscores            flat_event_df = pandas.json_normalize(event)            #Rename `id` to `strava_id`            flat_event_df.rename(columns={"id":"strava_id"}, inplace=True)            colnames = flat_event_df.columns.values            colnames_to_fix = dict([(original, original.replace(".", "_")) for original in colnames if "." in original])            flat_event_df.rename(columns = colnames_to_fix, inplace=True)            flat_event_dict = flat_event_df.iloc[0,:].to_dict()            #Convert start_date and start_date_local to datetime objects            flat_event_dict["start_date"] = datetime.datetime.fromisoformat(flat_event_dict["start_date"].rstrip("Z"))            flat_event_dict["start_date_local"] = datetime.datetime.fromisoformat(flat_event_dict["start_date_local"].rstrip("Z"))            #Unpack tuple fields            try:                flat_event_dict["start_lat"] = flat_event_dict["start_latlng"][0]                flat_event_dict["start_lng"] = flat_event_dict["start_latlng"][1]                flat_event_dict["end_lat"] = flat_event_dict["end_latlng"][0]                flat_event_dict["end_lng"] = flat_event_dict["end_latlng"][1]            except:                flat_event_dict["start_lat"] = None                flat_event_dict["start_lng"] = None                flat_event_dict["end_lat"] = None                flat_event_dict["end_lng"] = None            del flat_event_dict["start_latlng"]            del flat_event_dict["end_latlng"]            #Convert boolean fields to text            for bool_key in boolean_field_names:                try:                    flat_event_dict[bool_key] = str(flat_event_dict[bool_key])                except KeyError:                    flat_event_dict[bool_key] = None            #Select only fields that exist in our global fields_list set at the top            output_attribute_list = []            for field in ordered_field_names:                try:                    output_attribute_list.append(flat_event_dict[field])                except KeyError:                    output_attribute_list.append(None) #insert None if the field doesn't exist            #Let's decode the polyline into a list of (lon, lat) tuples            try:                decoded_polyline = polyline.decode(r"{0}".format(activity_polyline), geojson=True) #geojson returns (lon, lat) for Arcpy                if len(decoded_polyline) == 0:                    continue #skip events with a null decoded output                else:                    decoded_polyline = [(float(x), float(y)) for x,y in decoded_polyline] #Convert strings to floats                event_dictionary = {"coord_list":decoded_polyline, "attributes":output_attribute_list}                list_of_event_dictionaries.append(event_dictionary)            except Exception as e:                arcpy.AddWarning(f"An error occurred when decoding polyline for Activity ID {activity_id} from {activity_start}. Skipping.")    if verbose:        plural = "s"*int(len(list_of_event_dictionaries) != 1)        arcpy.AddMessage(f"---- Decoded polylines into coordinate lists for {len(list_of_event_dictionaries)} activity route{plural}.")    return list_of_event_dictionariesdef generate_polyline_objects(list_of_event_dictionaries, srid, verbose):    '''    Given a list of dictionaries, with coordinate lists and attributes for each event,            create polyline objects.    Input:  `list_of_event_dictionaries`: a list of dictionaries, each containing an                key called `list_of_coords` with lon-lat tuples, and a key called `attributes` with metadata attributes list            `srid`: integer, used to generate spatial reference    Output: a list of dictionaries, with two keys:            `geometry`: a Polyline Geometry object            `attributes`: a dictionary of attributes    '''    if list_of_event_dictionaries is None:        return None #indicates error in previous function    list_of_dictionaries = []    for event in list_of_event_dictionaries:        list_of_coords = event['coord_list']        attributes_list = event['attributes']        if len(attributes_list) != len(ordered_field_names):            arcpy.AddWarning("Error: number of attributes for the event does not match the schema specified in the global fields list.\nSkipping this entry.")            continue        arrayOfPoints = arcpy.Array([arcpy.Point(x,y) for (x,y) in list_of_coords])        spatialRef = arcpy.SpatialReference(srid)        polylineGeometry = arcpy.Polyline(arrayOfPoints, spatialRef)        output_dict = {"geometry":polylineGeometry, "attributes":attributes_list}        list_of_dictionaries.append(output_dict)    if verbose:        arcpy.AddMessage(f"---- Created POLYLINE geometries for {len(list_of_dictionaries)} routes.")    return list_of_dictionariesdef create_feature_class_with_fields(out_path, out_fc_name, srid, verbose):    '''    Create an empty polyline feature class with the fields defined in this function.    Input: `out_path`: string, absolute path to workspace where feature class will go (geodatabase, or dataset)            `out_fc_name`: string, name of output feature class            `srid`: integer spatial reference id. Defaults to 4326    Output: returns arcpy.da.Describe() object for the newly created feature class    '''    spatialRefObj = arcpy.SpatialReference(srid)    ## Create empty feature class    created_fc = arcpy.management.CreateFeatureclass(out_path, out_fc_name, "POLYLINE", "", "", "", spatialRefObj)    if [out_fc_name] != arcpy.ListFeatureClasses(out_fc_name, "POLYLINE"):        arcpy.AddError(f"Feature class `{out_fc_name}` was not created properly. Does not exist in current workspace {arcpy.env.workspace}. Exiting.")        return None    ## Edit fields    try:        arcpy.management.AddFields(out_fc_name, fields_list)    except Exception as e:        arcpy.AddError(f"Error in adding fields to {out_fc_name}: {e}\nExiting.")        return None    created_fc_description = arcpy.da.Describe(created_fc)    if verbose:        name = created_fc_description["name"]        path = created_fc_description["path"]        arcpy.AddMessage(f"---- Created `{name}` at `{path}`. Returning Describe object.")    return created_fc_descriptiondef populate_feature_class(fc_name, list_of_geometry_dicts, verbose):    """    Populate a feature class with polyline geometries and fields.    Input: `fc_name`: string, name of newly created feature class with fields defined            `list_of_geometry_dicts`: list, each element is a dictionary with a geometry item and a list of field values    Output: returns an arcpy.da.Describe object of the modified feature class.    """    #Return None if fc_name is None, indicating that the previous function failed.    if fc_name is None:        return None    #Validate the feature class exists:    if arcpy.ListFeatureClasses(fc_name, "POLYLINE") == []:        arcpy.AddError(f"Output feature class `{fc_name}` does not exist in current workspace. Exiting.")        return None    row_fields = ["SHAPE@"] + ordered_field_names    with arcpy.da.InsertCursor(fc_name, row_fields, explicit=True) as insert_cursor:        expected_number_of_fields = len(ordered_field_names)        for event in list_of_geometry_dicts:            #Validate format            if "geometry" not in event.keys() or "attributes" not in event.keys():                arcpy.AddWarning(f"Encountered malformatted dictionary keys when attempting to populate feature class. Skipping event.")                continue            if len(event["attributes"]) != expected_number_of_fields:                arcpy.AddWarning("Number of attributes for the event doesn't match the required number defined in the fields schema. Skipping event.")                continue            try:                inserted_row = [event["geometry"]] + event["attributes"]                insert_cursor.insertRow(inserted_row)            except Exception as e:                arcpy.AddWarning("Failed performing insertRow() operation: " + e + "\nSkipping event.")    desc = arcpy.da.Describe(fc_name)    if verbose:        rows = arcpy.management.GetCount(fc_name)        arcpy.AddMessage(f"---- Successfully wrote {rows} rows to `{fc_name}`.")    return desc    